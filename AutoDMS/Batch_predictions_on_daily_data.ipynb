{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code pour prédictions en lot sur les données journalières sur modèle entrainé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying BigQuery for daily shortage prediction analysis...\n",
      "Querying and loading time = 15.34 s \n",
      "Request finished\n",
      "\n",
      "Preprocessing input data...\n",
      "Querying and loading time of training data = 9.16 s \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.datalab.bigquery as bq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "\n",
    "\n",
    "#Chargement des données à prédire depuis BQ dans un dataframe\n",
    "from google.cloud import bigquery\n",
    "client = bigquery.Client()                     #préparation du client pour interroger BigQuery et garder les data dans un pd.DataFrame\n",
    "\n",
    "print('Querying BigQuery for daily shortage prediction analysis...')\n",
    "\n",
    "sql_pred = \"\"\"\n",
    "SELECT DISTINCT * FROM `electric-armor-213817.Donnees_journalieres.Mise_en_Forme_Extract_journalier_MSTR_CSL`\n",
    "WHERE PREPARATION_DATE < CURRENT_DATE\n",
    "\"\"\"\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "data_to_predict = client.query(sql_pred).to_dataframe()         #Interrogation de BigQuery \n",
    "\n",
    "print('Querying and loading time = {:0.2f} s '.format(time() - start_time))\n",
    "print('Request finished\\n')\n",
    "\n",
    "\n",
    "\n",
    "print('Preprocessing input data...')\n",
    "\n",
    "\n",
    "\n",
    "# ------------------ Load Training data to preprocess data ------------------------------------\n",
    "sql_train = \"\"\"\n",
    "WITH\n",
    "  DMS AS (\n",
    "  SELECT\n",
    "    ROW_NUMBER() OVER(PARTITION BY date_pr__pa, Code_SAP ORDER BY FLAG_CF ASC) AS ROW,\n",
    "    FLAG_CF,\n",
    "    CAST(date_pr__pa AS DATE) AS DATE_PREPA,\n",
    "    Code_SAP,\n",
    "    Import_type,\n",
    "    Usine,\n",
    "    Base,\n",
    "    Index_Pareto,\n",
    "    Cause_Pareto\n",
    "  FROM\n",
    "    `electric-armor-213817.Archives_DMS.DMS_2019_07_30`\n",
    "  GROUP BY\n",
    "    FLAG_CF,\n",
    "    date_pr__pa,\n",
    "    Code_SAP,\n",
    "    Usine,\n",
    "    Import_type,\n",
    "    Base,\n",
    "    Index_Pareto,\n",
    "    Cause_Pareto )\n",
    "  #----------------------------------------------------------------------------\n",
    "SELECT DISTINCT\n",
    "  FLAG_CF,\n",
    "  PREPARATION_DATE,\n",
    "  PDT_COD,\n",
    "  PDT_DSC,\n",
    "IF\n",
    "  (Forecast_table.Transformable = 'OUI',\n",
    "    1,\n",
    "    0) AS TRANSFORMABLE,\n",
    "  IF(DATE_DIFF( PREPARATION_DATE,CAST(BDD_PDT.Product_launch_date AS DATE), MONTH) < 2 ,1,0) AS INNO,\n",
    "  IF(Reft = '01 Afh', 1,0) AS IMPLUSE,\n",
    "  BDD_PDT.Umbrella_Brand,\n",
    "  DMS.Import_type,\n",
    "  DMS.Usine,\n",
    "  PLT_COD,\n",
    "  PLT_DSC,\n",
    "  SUM(Forecast_table.Forecast_including_adjustments) OVER(PARTITION BY Forecast_table.date, SAP_code ) AS PREVISION_NATIONAL,\n",
    "  COMMANDE_NATIONAL,\n",
    "  ALLOUE_NATIONAL,\n",
    "  LIVRE_NATIONAL,\n",
    "  (ALLOUE_NATIONAL - LIVRE_NATIONAL) AS ECART_ALLOC_NATIONAL,\n",
    "  RUPTURE_NATIONAL,\n",
    "  RUPTURE_STKA_NATIONAL,\n",
    "IF\n",
    "  (SUM(Forecast_table.Forecast_including_adjustments) OVER(PARTITION BY Forecast_table.date, SAP_code ) = 0,\n",
    "    1,\n",
    "    0) AS NO_FORECAST_NAT,\n",
    "  COMMANDE_NATIONAL - SUM(Forecast_table.Forecast_including_adjustments) OVER(PARTITION BY Forecast_table.date, SAP_code ) AS ECART_PREVISION_NAT,\n",
    "IF\n",
    "  (SUM(Forecast_table.Forecast_including_adjustments) OVER(PARTITION BY Forecast_table.date, SAP_code ) = 0,\n",
    "    90000,\n",
    "    -(SUM(Forecast_table.Forecast_including_adjustments) OVER(PARTITION BY Forecast_table.date, SAP_code ) - COMMANDE_NATIONAL)*100 / SUM(Forecast_table.Forecast_including_adjustments) OVER(PARTITION BY Forecast_table.date, SAP_code )) AS ECART_PREVISION_NAT_PERCENT,\n",
    "  COUNT(case when RUPTURE > 0 then 1 else null end) OVER(PARTITION BY Forecast_table.date, SAP_code) AS NB_OF_AFFECTED_DC,\n",
    "  Forecast_table.Forecast_including_adjustments AS PREVISION,\n",
    "  COMMANDE,\n",
    "  ALLOUE,\n",
    "  LIVRE,\n",
    "  (ALLOUE - LIVRE) AS ECART_ALLOC,\n",
    "  RUPTURE,\n",
    "  RUPTURE_STKA,\n",
    "IF\n",
    "  (Forecast_table.Forecast_including_adjustments = 0,\n",
    "    1,\n",
    "    0) AS NO_FORECAST,\n",
    "  COMMANDE - Forecast_table.Forecast_including_adjustments AS ECART_PREVISON,\n",
    "IF\n",
    "  (Forecast_table.Forecast_including_adjustments = 0,\n",
    "    10000,\n",
    "    -(Forecast_table.Forecast_including_adjustments - COMMANDE)*100 / Forecast_table.Forecast_including_adjustments) AS ECART_PREVISION_PERCENT,\n",
    "  CSL_ALLOC,\n",
    "  CSL,\n",
    "  CSL_ALLOC - CSL AS PERTE_CSL_vs_ALLOC,\n",
    "  CSL_ALLOC_NATIONAL,\n",
    "  CSL_NATIONAL,\n",
    "  CSL_ALLOC_NATIONAL - CSL_NATIONAL AS PERTE_CSL_vs_ALLOC_NATIONAL,\n",
    "  DMS.Cause_Pareto\n",
    "FROM\n",
    "  `electric-armor-213817.Archives_MicroStrategy.CSL_20181201_to_20190630_clean` AS MSTR_Archive_table,\n",
    "  `electric-armor-213817.Data_Forecasts.Data_Forecasts_CAR` AS Forecast_table,\n",
    "  `electric-armor-213817.Fichiers_produits.REFERENTIEL_PRODUITS_V2` AS BDD_PDT,\n",
    "  DMS\n",
    "WHERE\n",
    "  MSTR_Archive_table.PREPARATION_DATE = Forecast_table.date\n",
    "  AND MSTR_Archive_table.PLT_DSC = Forecast_table.DC\n",
    "  AND MSTR_Archive_table.PDT_COD = Forecast_table.SAP_code\n",
    "  AND MSTR_Archive_table.PDT_COD = BDD_PDT.Codification\n",
    "  AND MSTR_Archive_table.PREPARATION_DATE = DMS.DATE_PREPA\n",
    "  AND MSTR_Archive_table.PDT_COD = DMS.Code_SAP \n",
    "  AND IF(DMS.FLAG_CF = 0, TRUE, MSTR_Archive_table.PLT_DSC = DMS.Base)     #Condition sur quelle base joindre dans le cas ou j'ai une CF ou non (car top 10 donné sans la base)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "start_time = time()\n",
    "data = client.query(sql_train).to_dataframe()\n",
    "print('Querying and loading time of training data = {:0.2f} s \\n'.format(time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------Trainingset One Hot Encode of categorical data----------------------\n",
    "data = data.drop(['PREPARATION_DATE', 'PLT_COD', 'PDT_COD', 'PDT_DSC'], axis = 1)\n",
    "\n",
    "DC = pd.get_dummies(data.PLT_DSC)\n",
    "PLANT = pd.get_dummies(data.Usine)\n",
    "#MARQUE = pd.get_dummies(data.Umbrella_Brand)\n",
    "\n",
    "data = pd.concat([PLANT,DC,data], axis=1)\n",
    "data = data.drop(['PLT_DSC','Usine','Umbrella_Brand'], axis=1) \n",
    "\n",
    "training_feature_names = list(data)[:-1]            #le nom des colonnes des features d'entrainement\n",
    "training_target_name = list(data)[-1]                #le nom de la colonne des classes cibles\n",
    "\n",
    "#Put te Class_Name at the end of the DataFrame columns\n",
    "training_columns = list(np.sort(training_feature_names))      #on arrange les colonnes issues du set d'entrainement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------- Prediction data preprocessing -----------------------------------------\n",
    "#On conserve le DataFrame appelé 'data_to_predict' auquel on viendra ajouté ensuite les prédictions de l'algo\n",
    "#on crée un DataFrame intermédiaire appelé 'df_for_prediction' qui récupère les données journalières pour transformer les données catégoriques et ne va prendre que les colonnes du dataset d'entrainement\n",
    "\n",
    "\n",
    "#One Hot Encode des données catégoriques (Usine, DC) pour \n",
    "DC_pred = pd.get_dummies(data_to_predict.PLT_DSC)\n",
    "PLANT_pred = pd.get_dummies(data_to_predict.Usine)\n",
    "#MARQUE = pd.get_dummies(data.Umbrella_Brand)\n",
    "\n",
    "df_for_prediction = pd.concat([PLANT_pred,DC_pred,data_to_predict], axis=1)\n",
    "\n",
    "df_for_prediction = df_for_prediction[training_columns]\n",
    "df_for_prediction = df_for_prediction.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataframe has  60  features plus one target column\n",
      "Prediction dataframe has  60  features\n",
      "Data Preprocessing finished\n"
     ]
    }
   ],
   "source": [
    "print('Training dataframe has ',data.shape[1]-1, ' features plus one target column')\n",
    "print('Prediction dataframe has ',df_for_prediction.shape[1], ' features')\n",
    "\n",
    "if data.shape[1]-1 != df_for_prediction.shape[1]:\n",
    "    raise ValueError(\"Number of features between training set and prediction set is different\")\n",
    "\n",
    "    \n",
    "#On veut prédire la classe de toutes les ruptures, on conserve donc les données dans une liste que l'on fera passer dasn l'algo\n",
    "X_to_predict = df_for_prediction.iloc[:, :].values\n",
    "\n",
    "print('Data Preprocessing finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch prediction of daily shortages...\n",
      "Batch prediction finished\n"
     ]
    }
   ],
   "source": [
    "print('Batch prediction of daily shortages...')\n",
    "\n",
    "#---------------------------- Choose which model to load -------------------\n",
    "#get the trained model\n",
    "from joblib import load\n",
    "model = load('trained_XGB_V2.joblib')\n",
    "\n",
    "\n",
    "\n",
    "#Perform predictions and get probabilities\n",
    "y_to_predict = model.predict(X_to_predict)\n",
    "y_to_predict_proba = model.predict_proba(X_to_predict)\n",
    "\n",
    "y_to_predict_proba = np.amax(y_to_predict_proba, axis=1)\n",
    "\n",
    "Y_to_predict_df = pd.DataFrame( {\"Class_Prediction\":y_to_predict})\n",
    "Y_to_predict_proba_df = pd.DataFrame( {\"Class_Prediction_probability\":y_to_predict_proba})\n",
    "\n",
    "#Build the predicted Pandas DataFrame\n",
    "Final_predicted_df = pd.concat([data_to_predict,Y_to_predict_df,Y_to_predict_proba_df], axis=1)\n",
    "\n",
    "Final_predicted_df = Final_predicted_df.dropna()\n",
    "\n",
    "print('Batch prediction finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------ Retravail des prédictions -----------------------\n",
    "\n",
    "def flag_rupture(row):\n",
    "    #Fonction qui flag lorsqu'il n'y a pas de rupture\n",
    "    val=0\n",
    "    if row['RUPTURE'] > 0:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val\n",
    "\n",
    "def flag_livraison(row):\n",
    "    #fonction qui va passer la classe à \"Livré\" si RUPTURE = 0\n",
    "    classe=row['Class_Prediction']\n",
    "    if row['RUPTURE'] == 0:\n",
    "        classe = 'Livré'\n",
    "    else:\n",
    "        pass\n",
    "    return classe\n",
    "        \n",
    "\n",
    "def rejet_cause_prev(row):\n",
    "    #fonction qui rejete de la cause prévisions une rupture qui présente Prev>Commande \n",
    "    #ou pour lequel l'écart de prévision national est nul\n",
    "    #ou pour lequel le CSL_alloc_National est de 100%\n",
    "    classe = row['Class_Prediction']\n",
    "    proba = row['Class_Prediction_probability']\n",
    "    if (((row['PREVISION'] > row['COMMANDE'])  | (row['CSL_ALLOC_NATIONAL'] == 100.0) | (row['ECART_PREVISION_NAT_PERCENT'] == 0.0)) & (classe == 'Previsions')):\n",
    "        classe = \"A Creuser\"\n",
    "        proba = 1\n",
    "    else:\n",
    "        pass\n",
    "    return classe    #il faudrait aussi modifier la probabilité à 1 mais je ne sais pas encore comment le faire\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Application de ces règles au dataframe\n",
    "Final_predicted_df['FLAG_RUPTURE'] = Final_predicted_df.apply(flag_rupture, axis=1)\n",
    "\n",
    "Final_predicted_df['Class_Prediction'] = Final_predicted_df.apply(rejet_cause_prev, axis=1)\n",
    "\n",
    "Final_predicted_df['Class_Prediction'] = Final_predicted_df.apply(flag_livraison, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export to BigQuery table...\n",
      "BigQuery export finished. \n",
      "Exporting process took 2.23min\n"
     ]
    }
   ],
   "source": [
    "print('Export to BigQuery table...')\n",
    "start_time = time()\n",
    "\n",
    "#Export vers BigQuery\n",
    "bigquery_dataset_name = 'electric-armor-213817.Donnees_journalieres'\n",
    "bigquery_table_name = 'Classification_journaliere'\n",
    "\n",
    "# Define BigQuery dataset and table\n",
    "dataset = bq.Dataset(bigquery_dataset_name)\n",
    "table = bq.Table(bigquery_dataset_name + '.' + bigquery_table_name)\n",
    "\n",
    "\n",
    "# Create or overwrite the existing table if it exists\n",
    "table_schema = bq.Schema.from_data(Final_predicted_df)\n",
    "table.create(schema = table_schema, overwrite = True)\n",
    "\n",
    "# Write the DataFrame to a BigQuery table\n",
    "table.insert(Final_predicted_df)\n",
    "print('BigQuery export finished. \\nExporting process took {:0.2f}min'.format((time()-start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
